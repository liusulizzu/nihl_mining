{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "172f8798-93b7-4619-8c88-281ef796eb0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "\n",
    "from tensorflow import feature_column\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "347a0951-51e1-4391-bed1-a4e0afdcded6",
   "metadata": {},
   "source": [
    "## 线性模型\n",
    "使用逻辑回归模型来进行预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39aff21a-c2b7-4561-9e20-be8f7e7e5433",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_allowed_snp_names():\n",
    "    df = pd.read_csv('allowed_snp.csv')\n",
    "    df['snp'] = df['snp'].apply(lambda x : x.split('_')[1])\n",
    "    df = df.sort_values(by=['snp'])\n",
    "    snps = df['snp'].tolist()\n",
    "    return snps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644dd67e-8541-4102-8211-6d7f7a69edd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def value_to_int(hl):\n",
    "    if hl>=0 and hl<10:\n",
    "        return 0\n",
    "    if hl>=10 and hl<20:\n",
    "        return 1\n",
    "    if hl>=20 and hl<30:\n",
    "        return 2\n",
    "    if hl>=30 and hl<40:\n",
    "        return 3\n",
    "    if hl>=40 and hl<50:\n",
    "        return 4\n",
    "    if hl>=50 and hl<60:\n",
    "        return 5\n",
    "    if hl>=60 and hl<70:\n",
    "        return 6\n",
    "    if hl>=70 and hl<80:\n",
    "        return 7\n",
    "    if hl>=80 and hl <90:\n",
    "        return 8\n",
    "    return 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a341b0c-0a90-418b-bd51-70a0c5c6a75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_dataset(dataframe, shuffle=True, batch_size=32):\n",
    "    dataframe = dataframe.copy()\n",
    "    labels = dataframe.pop('caco')\n",
    "    #dataframe['HL'] = dataframe['HL'].map(value_to_int)\n",
    "    #labels = dataframe.pop('HL')\n",
    "    dataframe.pop('Simple Name')\n",
    "    ds = tf.data.Dataset.from_tensor_slices((dict(dataframe), labels))\n",
    "    ds.repeat()\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(buffer_size=len(dataframe))\n",
    "        ds = ds.batch(batch_size)\n",
    "    #it = ds.make_initializable_iterator()\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d38293-4ad4-4b25-84c6-2f639ebe1d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_input_fn(file):\n",
    "    # 生成输入样本\n",
    "    df = pd.read_csv(file)\n",
    "    df = df.dropna()\n",
    "    return df_to_dataset(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11338165-1452-47e0-a8e5-2c7b2bd50359",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_all_input_fn():\n",
    "    df = pd.read_csv('1.csv')\n",
    "    df = df.dropna()\n",
    "    df1 = pd.read_csv('2.csv')\n",
    "    df1 = df1.dropna()\n",
    "    final_df = pd.concat([df, df1], ignore_index=True)\n",
    "    #######开始剔除错误数据###########\n",
    "    final_case_df = final_df[(final_df['caco'] == 1) & (final_df['HL'] >= 40)]\n",
    "    final_control_df = final_df[(final_df['caco'] == 0) & (final_df['HL']) < 40]\n",
    "    final_df = pd.concat([final_case_df, final_control_df], ignore_index=True)\n",
    "    final_df = final_df[final_df['age']>10]\n",
    "    ######end######################\n",
    "    #######开始正则化#####\n",
    "    final_df['CNE'] = (final_df['CNE']-final_df['CNE'].mean())/final_df['CNE'].std()\n",
    "    final_df['age'] = (final_df['age']-final_df['age'].mean())/final_df['age'].std()\n",
    "    final_df['BMI'] = (final_df['BMI']-final_df['BMI'].mean())/final_df['BMI'].std()\n",
    "    final_df['HL'] = (final_df['HL']-final_df['HL'].mean())/final_df['HL'].std()\n",
    "    \n",
    "    ######end###########\n",
    "    final_df = final_df.sample(frac=1).reset_index(drop=True)\n",
    "    final_train_dataset = final_df.sample(frac=0.9, random_state=0, axis=0)\n",
    "    final_test_dataset = final_df[~final_df.index.isin(final_train_dataset.index)]\n",
    "    final_test_dataset.to_csv('test.csv')\n",
    "    #return df_to_dataset(final_train_dataset)\n",
    "    return df_to_dataset(final_train_dataset), df_to_dataset(final_test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a07360-013e-47ae-a51f-66d8fda2e69f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义所有的feature\n",
    "def get_feature_columns():\n",
    "    features = []\n",
    "    \n",
    "    cne_feature = feature_column.numeric_column('CNE')  #累积噪声量\n",
    "    category_cne = feature_column.bucketized_column(cne_feature, [85, 90, 95, 100, 105, 110])\n",
    "    features.append(cne_feature)\n",
    "    \n",
    "    age_feature = feature_column.numeric_column('age') # 年龄\n",
    "    category_age_feature = feature_column.bucketized_column(age_feature, [20, 25, 30, 35, 40, 45, 50, 55])\n",
    "    features.append(age_feature)\n",
    "    \n",
    "    sex_feature = feature_column.categorical_column_with_vocabulary_list('sex', [1, 2])\n",
    "    sex_feature_one_hot = feature_column.indicator_column(sex_feature)\n",
    "    features.append(sex_feature_one_hot)\n",
    "    \n",
    "    smoke_feature = feature_column.categorical_column_with_vocabulary_list('smoke', [1, 0])\n",
    "    smoke_feature_one_hot = feature_column.indicator_column(smoke_feature)\n",
    "    features.append(smoke_feature_one_hot)\n",
    "    \n",
    "    drink_feature = feature_column.categorical_column_with_vocabulary_list('drink', [1, 0])\n",
    "    drink_feature_one_hot = feature_column.indicator_column(drink_feature)\n",
    "    features.append(drink_feature_one_hot)\n",
    "    \n",
    "    excercise_feature = feature_column.categorical_column_with_vocabulary_list('excercise', [1, 0])\n",
    "    excercise_feature_one_hot = feature_column.indicator_column(excercise_feature)\n",
    "    features.append(excercise_feature_one_hot)\n",
    "    \n",
    "    hp_feature = feature_column.categorical_column_with_vocabulary_list('HP', [1, 0])\n",
    "    hp_feature_one_hot = feature_column.indicator_column(hp_feature)\n",
    "    features.append(hp_feature_one_hot)\n",
    "    \n",
    "    bmi_feature = feature_column.numeric_column('BMI')\n",
    "    category_bmi_feature = feature_column.bucketized_column(bmi_feature, [15, 20, 25, 30, 35, 40])\n",
    "    features.append(category_bmi_feature)\n",
    "    \n",
    "    rs1358714_x_rs1200130_feature = feature_column.crossed_column(['rs1358714', 'rs1200130'], 9)\n",
    "    features.append(feature_column.indicator_column(rs1358714_x_rs1200130_feature))\n",
    "    \n",
    "    rs17412009_x_rs1200130_feature = feature_column.crossed_column(['rs17412009', 'rs1200130'], 9)\n",
    "    features.append(feature_column.indicator_column(rs17412009_x_rs1200130_feature))\n",
    "    \n",
    "    rs2070703_x_rs1200130_feature = feature_column.crossed_column(['rs2070703', 'rs1200130'], 9)\n",
    "    features.append(feature_column.indicator_column(rs2070703_x_rs1200130_feature))\n",
    "    \n",
    "    rs6458080_x_rs1200130_feature = feature_column.crossed_column(['rs6458080', 'rs1200130'], 9)\n",
    "    features.append(feature_column.indicator_column(rs6458080_x_rs1200130_feature))\n",
    "    \n",
    "    rs17412009_x_rs1200135_feature = feature_column.crossed_column(['rs17412009', 'rs1200135'], 9)\n",
    "    features.append(feature_column.indicator_column(rs17412009_x_rs1200135_feature))\n",
    "    \n",
    "    rs1200137_x_rs6458080_feature = feature_column.crossed_column(['rs1200137', 'rs6458080'], 9)\n",
    "    features.append(feature_column.indicator_column(rs1200137_x_rs6458080_feature))\n",
    "    \n",
    "    rs17412009_x_rs1358714_feature = feature_column.crossed_column(['rs17412009', 'rs1358714'], 9)\n",
    "    features.append(feature_column.indicator_column(rs17412009_x_rs1358714_feature))\n",
    "    \n",
    "    rs6458080_x_rs1678690_x_sex_feature = feature_column.crossed_column(['rs6458080', 'rs1678690','sex'], 18)\n",
    "    features.append(feature_column.indicator_column(rs6458080_x_rs1678690_x_sex_feature))\n",
    "    \n",
    "    rs17412009_x_rs6458080_x_sex_feature = feature_column.crossed_column(['rs17412009', 'rs6458080','sex'], 18)\n",
    "    features.append(feature_column.indicator_column(rs17412009_x_rs6458080_x_sex_feature))\n",
    "    \n",
    "    \n",
    "    rs1200137_x_rs17412009_x_rs1200135_feature = feature_column.crossed_column(['rs1200137', 'rs17412009','rs1200135'], 27)\n",
    "    features.append(feature_column.indicator_column(rs1200137_x_rs17412009_x_rs1200135_feature))\n",
    "\n",
    "    rs17412009_x_rs1200135_x_rs1358714_feature = feature_column.crossed_column(['rs17412009', 'rs1200135','rs1358714'], 27)\n",
    "    features.append(feature_column.indicator_column(rs17412009_x_rs1200135_x_rs1358714_feature))\n",
    "\n",
    "    rs1200137_x_rs17412009_x_rs1358714_feature = feature_column.crossed_column(['rs1200137', 'rs17412009','rs1358714'], 27)\n",
    "    features.append(feature_column.indicator_column(rs1200137_x_rs17412009_x_rs1358714_feature))\n",
    "    \n",
    "    rs1200137_x_rs1200135_x_rs1358714_feature = feature_column.crossed_column(['rs1200137', 'rs1200135','rs1358714'], 27)\n",
    "    features.append(feature_column.indicator_column(rs1200137_x_rs1200135_x_rs1358714_feature))\n",
    "    \n",
    "    smoke_x_sex_feature = feature_column.crossed_column(['sex', 'smoke'], 4)\n",
    "    features.append(feature_column.indicator_column(smoke_x_sex_feature))\n",
    "    \n",
    "    rs1200137_x_rs1200130_x_sex = feature_column.crossed_column(['sex', 'rs1200137', 'rs1200130'], 18)\n",
    "    features.append(feature_column.indicator_column(rs1200137_x_rs1200130_x_sex))\n",
    "    \n",
    "    rs159153_x_rs1200130_x_sex = feature_column.crossed_column(['sex', 'rs159153', 'rs1200130'], 18)\n",
    "    features.append(feature_column.indicator_column(rs159153_x_rs1200130_x_sex))\n",
    "    \n",
    "    rs17412009_x_rs1200130_x_sex = feature_column.crossed_column(['sex', 'rs17412009', 'rs1200130'], 18)\n",
    "    features.append(feature_column.indicator_column(rs17412009_x_rs1200130_x_sex))\n",
    "    \n",
    "    rs34996498_x_rs1200130_x_sex = feature_column.crossed_column(['sex', 'rs34996498', 'rs1200130'], 18)\n",
    "    features.append(feature_column.indicator_column(rs34996498_x_rs1200130_x_sex))\n",
    "    \n",
    "    rs3766031_x_rs1200130_x_sex = feature_column.crossed_column(['sex', 'rs3766031', 'rs1200130'], 18)\n",
    "    features.append(feature_column.indicator_column(rs3766031_x_rs1200130_x_sex))\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    # hl_feature = feature_column.numeric_column('HL')\n",
    "    # features.append(hl_feature)\n",
    "    \n",
    "    valid_snp_names = get_allowed_snp_names()\n",
    "    \n",
    "    snp_ga = ('rs10091503', 'rs1026435', 'rs10503675', \n",
    "              'rs11778205', 'rs1200135', 'rs1358714', 'rs1678674',\n",
    "              'rs1738254', 'rs3737094', 'rs3807154', 'rs3823430', \n",
    "              'rs4452640', 'rs874808', 'rs9357283','rs3745504','rs4801822','rs34996498')\n",
    "    snp_gc = ('rs1678690','rs919390','rs378811','rs3872717','rs7621556') # C/C G/C G/G\n",
    "    snp_tg=('rs627491')\n",
    "    snp_ta=('rs7641176')\n",
    "    \n",
    "    for snp in valid_snp_names:\n",
    "        if snp in snp_ga:\n",
    "            snp_feature = feature_column.categorical_column_with_vocabulary_list(snp, ['G/A', 'G/G', 'A/A' ])\n",
    "        elif snp in snp_gc:\n",
    "            snp_feature = feature_column.categorical_column_with_vocabulary_list(snp, ['C/C', 'G/G', 'G/C' ])\n",
    "        elif snp in snp_tg:\n",
    "            snp_feature = feature_column.categorical_column_with_vocabulary_list(snp, ['T/G', 'G/G', 'T/T' ])\n",
    "        elif snp in snp_ta:\n",
    "            snp_feature = feature_column.categorical_column_with_vocabulary_list(snp, ['A/A', 'T/A', 'T/T' ])\n",
    "        else:\n",
    "            snp_feature = feature_column.categorical_column_with_vocabulary_list(snp, ['C/C', 'T/C', 'T/T' ])\n",
    "        snp_feature_one_hot = feature_column.indicator_column(snp_feature)\n",
    "        features.append(snp_feature_one_hot)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6deb0b90-678e-4ef1-88d8-54c885d59b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 建立逻辑回归模型\n",
    "def build_model(feature_columns):   \n",
    "    model=tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.DenseFeatures(feature_columns))\n",
    "    model.add(tf.keras.layers.Dense(32, activation = 'relu', name='layer1'))\n",
    "    model.add(tf.keras.layers.Dense(1,activation='sigmoid',name='last_layer'))\n",
    "    model.compile(optimizer = tf.keras.optimizers.Adagrad(lr=0.001),\n",
    "                  loss = tf.keras.losses.BinaryFocalCrossentropy(),\n",
    "                  metrics=['AUC'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf37c53-757e-49a1-8ad6-c6b8050e6606",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns = get_feature_columns()\n",
    "model = build_model(feature_columns)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb793d4f-8dc0-4b23-9b60-e178ec730191",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练和评估模型\n",
    "def train_and_eval_model(batch_size=20):\n",
    "    feature_columns = get_feature_columns()\n",
    "    model = build_model(feature_columns)\n",
    "    trainset, test_set = build_all_input_fn()\n",
    "    model.fit(x=trainset, \n",
    "              epochs=200,\n",
    "              validation_data=test_set,\n",
    "              callbacks=[tf.keras.callbacks.TensorBoard(log_dir='./linear_model_logs')])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1f63dd-5534-4196-8fec-a81c6b485c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = train_and_eval_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd06afc0-7394-4a7d-8c2a-b4af4ee23b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('./save_models/20220213/v3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "501b1c67-a876-46c1-be97-899640a2d1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24741c38-6a76-47c2-b2ef-44cdc72703c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_test_set(model):\n",
    "    df = pd.read_csv('test.csv')\n",
    "    df.pop('Unnamed: 0')\n",
    "    df.pop('Simple Name')\n",
    "    labels = df.pop('caco')\n",
    "    df = df.dropna()\n",
    "    ds = tf.data.Dataset.from_tensor_slices((dict(df), labels))\n",
    "    ds.batch(20)\n",
    "    print(ds)\n",
    "    return model(dict(df))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab8a577c-3e4e-42d3-9ef0-5cdcdbda8980",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_test_set(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae97be9a-a534-4828-a215-3c10f5fe8599",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = build_all_input_fn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "020f9a2b-df9f-4a13-9afc-ccca22ae523d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e371c17c-ac71-40ab-b559-e4ab2ac75d49",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
